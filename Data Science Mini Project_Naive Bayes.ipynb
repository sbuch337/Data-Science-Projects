{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Name: Stephanie Buchanan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import all packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import nltk\n",
    "import contractions\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prepocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam             0\n",
       "email_message    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the data\n",
    "emails = pd.read_csv('spam.csv')\n",
    "emails.drop('FILE_NAME', axis = 1, inplace = True)\n",
    "emails.columns = ['spam', 'email_message']\n",
    "\n",
    "#check for missing data\n",
    "emails.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text, stopwords):\n",
    "    # remove tags like <tab>\n",
    "    text = re.sub(r'<[^<>]*>', ' ', text) \n",
    "    # split text on whitespace\n",
    "    text_list = text.split()\n",
    "    expanded_words = []\n",
    "    text_words = []\n",
    "    \n",
    "    punctuation = set(string.punctuation)\n",
    "    punctuation.add(\"“\")\n",
    "    punctuation.add(\"”\")\n",
    "    \n",
    "    # keep #tags and @mentions\n",
    "    ## punctuation.remove(\"#\")\n",
    "    ## punctuation.remove(\"@\")\n",
    "    \n",
    "    for word in text_list:\n",
    "        expanded_words.append(contractions.fix(word))\n",
    "    \n",
    "    for word in expanded_words:\n",
    "        # remove punctuation marks at the beginning\n",
    "        # of each word\n",
    "        while len(word) > 0 and word[0] in punctuation:\n",
    "            word = word[1:]\n",
    "        # remove punctuation marks at the end of each word\n",
    "        while len(word) > 0 and word[-1] in punctuation: \n",
    "            word = word[:-1]\n",
    "        # a rule to eliminate most urls\n",
    "        if len(word) > 0 and \"/\" not in word: \n",
    "            # eliminate stopwords\n",
    "            if word.lower() not in stopwords:\n",
    "                # append the word to the text_words list\n",
    "                text_words.append(word.lower())\n",
    "    \n",
    "    cleaner_text = ' '.join([lemmatizer.lemmatize(w) for w in text_words])\n",
    "    \n",
    "    return cleaner_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails['email_message'] = emails['email_message'].apply(clean, stopwords=sw) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_data = emails[emails['email_message'].str.len() > 60] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_em, X_test_em, y_train_em, y_test_em = train_test_split(emails_data['email_message'],emails_data['spam'], \n",
    "                                                                        test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building and Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross validation score: 0.9826\n",
      "Standard deviation of cross validation scores: 0.0042\n"
     ]
    }
   ],
   "source": [
    "tfidf2 = TfidfVectorizer(ngram_range=(1,2), stop_words=\"english\", min_df=10, max_features=None)\n",
    "email_pipe = Pipeline([(\"tfidf\",tfidf2), (\"mnb\", MultinomialNB())])\n",
    "email_pipe.fit(X_train_em, y_train_em)\n",
    "\n",
    "scores_em = cross_val_score(estimator=email_pipe, X=X_train_em, y=y_train_em, cv=5) \n",
    "\n",
    "print(f'Average cross validation score: {scores_em.mean():.4f}')\n",
    "print(f'Standard deviation of cross validation scores: {scores_em.std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy for Email Multinomial NB model: 0.9871\n",
      "Test accuracy for Email Multinomial NB model: 0.9823\n"
     ]
    }
   ],
   "source": [
    "print(f'Training accuracy for Email Multinomial NB model: {email_pipe.score(X_train_em, y_train_em):.4f}')\n",
    "print(f'Test accuracy for Email Multinomial NB model: {email_pipe.score(X_test_em, y_test_em):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('tfidf',\n",
       "                                        TfidfVectorizer(min_df=10,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        stop_words='english')),\n",
       "                                       ('mnb', MultinomialNB())]),\n",
       "             param_grid=[{'mnb__alpha': [0.1, 0.01, 0.001],\n",
       "                          'mnb__fit_prior': [True, False],\n",
       "                          'tfidf__min_df': [5, 20],\n",
       "                          'tfidf__ngram_range': [(1, 1), (1, 2)]}])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_em = [{'mnb__alpha': [0.1, 0.01, 0.001],\n",
    "                   'mnb__fit_prior': [True, False],\n",
    "                   'tfidf__min_df':[5, 20],\n",
    "                   'tfidf__ngram_range':[(1, 1), (1, 2)]}]\n",
    "\n",
    "grid_em = GridSearchCV(estimator=email_pipe, param_grid =param_grid_em, cv=3) \n",
    "\n",
    "grid_em.fit(X_train_em, y_train_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params:  {'mnb__alpha': 0.01, 'mnb__fit_prior': False, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 2)}\n",
      "Training accuracy for Multinomial Grid Search: 0.9970\n",
      "Test accuracy for Multinomial Grid Search: 0.9929\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Params: \", grid_em.best_params_)\n",
    "print(f'Training accuracy for Multinomial Grid Search: {grid_em.score(X_train_em, y_train_em):.4f}')\n",
    "print(f'Test accuracy for Multinomial Grid Search: {grid_em.score(X_test_em, y_test_em):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project was aimed at classifying different email messages as either spam or not-spam.  The dataset was a labeled dataset, and the attributes were the email text and the spam label.  There was also a 'file name' attribute that contained a unique identifier for each email messgae that was dropped from the dataset to simplify the data.\n",
    "\n",
    "A Multinomial Naive Bayes classifer was selected to classify email messages as spam or not-spam.  The email messages were cleaned for punctuation, the contractions were expanded, the words were lemmatized and the stopwords were removed.  The text was also vectorized using the TfidfVectorizer, which applies a weight to the tokens with higher weights given to more infrequent words relative to the whole corpus.  \n",
    "\n",
    "The initial model performed well at a 98.3% accuracy using cross-validation with 5-folds. Overfitting was not observed as the training and test scores were both very similar.  A grid search was performed to tune the 'alpha' and 'fit_prior' paramters for the classifier, and the 'min_df' and 'ngram_range' parameters for the TfidfVectorizer.  'Alpha' is the Laplace smoothing parameter, and the 'fit_prior' parameter is a boolean representing whether to learn class prior probabilities or not.  The 'min_df' represents the number of documents that is the threshold, thus instructs the algorithm to ignore terms that have a document frequency strictly lower than the given value. The 'ngram_range' parameter gives the upper and lower range for the n-grams to be extracted.\n",
    "\n",
    "In conclusion, the Multinomial Naive Bayes classifier is a good choice for detecting spam from email messages.  The training accuracy with the parameters: {'mnb__alpha': 0.01, 'mnb__fit_prior': False, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 2)} was 99.7% and the test accuracy was 99.3%.  Overfitting does not seem to be present in this model due to the fact the testing and test accuracies were very similar and not significantly different.  This model can be used to classify future email messages as spam or not-spam."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
